Lab6 IDS

-trebuie sa gasim 4 set-uri de date
-2 set-uri de date trebuie neaparat sa aibe valori lipsa

1. pe un set de date cu valori lipsa trebuie sa bagam o metoda de missing value inputation
-metoda trebuie sa fie justificata si documentata
-fill, nu aruncam coloanele sau liniile

2. pentru toate cele 4 set-uri de date trebuie sa aplicam 5 metode de clasificare
-metodele de clasificare le alegem din .pdf (sunt 8)
-pentru fiecare metoda raportam acuratete, scorul F1 cu 5-fold cross validation
-folosim hiperparametri pentru metode alese de noi
-trebuie sa afisam mediile rezultatelor pentru rularile pe setul de antrenare si pentru rularile pe setul de testare

3. documentam in limba romana fiecare din cele 5 metode de clasificare, eventual intr-o sectiune separata din notebook

4. rulam din nou cele 5 metode de clasificare cu 5-fold cross validation si raportam performanta
-pentru fiecare fold din cele 5 cautam parametri optimi prin 4-fold validation si raportam performanta ca media celor 5 rulari

-trebuie sa alegem 5 metode de clasificare
-trebuie sa alegem 4 seturi de date, 2 si 2
-partea de documentatie putem sa o facem separat

Luate:>
-KNN
-Multi-layer perceptron
-SVM
-Decision tree
-Random forest

Date:
-Semeion
-SpamBase
-Wine
.datele trebuie scalate pentru ca sunt intre ordinul zecilor si ordinul miilor
.y nu trebuie scalat pentru ca reprezinta clasa de care apartine exemplul de antrenare (training example)

Date:
-fara missing: Wine

TO KNOW:
-scalarea datelor si de ce am facut-o
-skip_header ce face
-train_test_split(), eventual si parametrul "test_size", "random_state"
-fit()
-predict()
-cum se calculeaza accuracy din metrics
-cross_val_score(), eventual si parametrul scoring cu "average", "weighted", "f1_macro"
-ce e aia mean()
-ce fac parametrii lui GridSearchCV

pt algoritmi:
KNN:
-ce face n_neighbours
DecisionTree
-se calculeaza impuritatea Gini pentru a determina care feature sa folosim la radacina arborelui
-feature care da cea mai mica impuritate e folosit la radacina
-un nod nu se mai desparte daca are cea mai mica impuritate, nu mai are sens sa iei alta trasatura in considerare pentru ca trasatura respectiva nu ajuta la scadearea valorii impuritatii [13.05]
-e o idee sa il lasi sa ruleze fara parametri si sa vezi daca face underfit sau overfit si apoi sa incerci sa modifici hiperparametrii, in special max_depth
-parametrul min_samples_leaf e mereu luat in considerare indiferent de parametrul min_samples_split
-min_samples_split controleaza situatia de overfit
Random forest
-o extensie a DecisionTree
-mai versatil
-out-of-bag-dataset = setul de date care nu a intrat in setul de date bootstrapped
-putem folosi out-of-bag-dataset ca sa testam modelul si cate sample-uri sunt clasificate corect ne da acuratetea modelului
-se incepe folosind radical(n) variabile (trasaturi) si se incearca apoi mai multe sau mai putine

Notes:
-best_params_ devine valabil dupa ce faci un fit
-return_train_score=True avem nevoie de el cand vrem sa punem intr-un pd data frame cv_results_
-daca y contine clasa din care face parte modelul, cum e la iris, nu cred ca trebuie scalare pe y

TO DOs:
-4 algorithms
-sa fac un pipeline [X]
