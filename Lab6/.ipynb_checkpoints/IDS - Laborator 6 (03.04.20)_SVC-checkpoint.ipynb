{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laborator 6\n",
    "\n",
    "Versiunea 2020-04-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modele de clasificare\n",
    "\n",
    "Folositi 4 seturi de date pentru probleme de clasificare, plecand de la repository-urile specificate in Cursul 5; de exemplu, [ics.uci.edu](http://archive.ics.uci.edu/ml/datasets.php?format=mat&task=cla&att=&area=&numAtt=&numIns=&type=mvar&sort=nameUp&view=table). Cel putin doua seturi de date sa fie cu valori lipsa. \n",
    "\n",
    "\n",
    "1. (20 puncte) Aplicati o metoda de missing value imputation, unde este cazul; justificati si documentati metoda folosita.\n",
    "1. (numar de modele * numar de seturi de date \\* 1 punct = 20 de puncte) Pentru fiecare set de date aplicati 5 modele de clasificare din scikit learn. Pentru fiecare raportati: acuratete, scorul F1 - a se vedea [sklearn.metrics](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) - folosind 5 fold cross validation. Raportati mediile rezultatelor atat pentru fold-urile de antrenare, cat si pentru cele de testare. Rularile se vor face cu valori fixate ale hiperparametrilor. \n",
    "1. (numar modele * 4 puncte = 20 puncte) Documentati in jupyter notebook fiecare din modelele folosite, in limba romana. Daca acelasi algoritm e folosit pentru mai multe seturi de date, puteti face o sectiune separata cu documentarea algoritmilor + trimitere la algoritm. \n",
    "1. (numar de modele * numar de seturi de date * 1 punct = 20 de puncte) Raportati performanta fiecarui model, folosind 5 fold cross validation. Pentru fiecare din cele 5 rulari, cautati hiperparametrii optimi folosind 4-fold cross validation. Performanta modelului va fi raportata ca medie a celor  5 rulari. \n",
    "    *Observatie:* la fiecare din cele 5 rulari, hiperparametrii optimi pot diferi, din cauza datelor utilizate pentru antrenare/validare. \n",
    "\n",
    "Se acorda 20 de puncte din oficiu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemple de modele de clasificare:\n",
    "1. [Multi-layer Perceptron classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)\n",
    "1. [KNN](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)\n",
    "1. [SVM](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)\n",
    "1. [Gaussian processes](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessClassifier.html#sklearn.gaussian_process.GaussianProcessClassifier)\n",
    "1. [RBF](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.RBF.html#sklearn.gaussian_process.kernels.RBF)\n",
    "1. [Decision tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)\n",
    "1. [Random forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)\n",
    "1. [Gaussian Naive bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy: 1.18.1\n",
      "pandas: 1.0.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print ('numpy:', np.__version__)\n",
    "print ('pandas:', pd.__version__)\n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Missing value imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Accuracy and F1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine Data Set\n",
    "#### (http://archive.ics.uci.edu/ml/datasets/Wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1     2     3     4    5     6     7     8     9     10    11    12  \\\n",
       "0   1  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29  5.64  1.04  3.92   \n",
       "1   1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28  4.38  1.05  3.40   \n",
       "2   1  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81  5.68  1.03  3.17   \n",
       "3   1  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18  7.80  0.86  3.45   \n",
       "4   1  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82  4.32  1.04  2.93   \n",
       "\n",
       "     13  \n",
       "0  1065  \n",
       "1  1050  \n",
       "2  1185  \n",
       "3  1480  \n",
       "4   735  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data = pd.read_csv(r'C:\\f_Projects\\II_Sem_2_V_REPOS\\IDS\\Lab6\\Data\\Wine\\wine.data', header=None)\n",
    "wine_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpret data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Wine = wine_data.values[:, 1:]\n",
    "y_Wine = wine_data.values[:, 0] #prima coloana reprezinta ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.03 \t 14.83\n",
      "0.74 \t 5.8\n",
      "1.36 \t 3.23\n",
      "10.6 \t 30.0\n",
      "70.0 \t 162.0\n",
      "0.98 \t 3.88\n",
      "0.34 \t 5.08\n",
      "0.13 \t 0.66\n",
      "0.41 \t 3.58\n",
      "1.28 \t 13.0\n",
      "0.48 \t 1.71\n",
      "1.27 \t 4.0\n",
      "278.0 \t 1680.0\n"
     ]
    }
   ],
   "source": [
    "def print_ranges(X):\n",
    "    for col_index in range(X.shape[1]):\n",
    "        column = X[:, col_index]\n",
    "        print(f'{np.min(column)} \\t {np.max(column)}')\n",
    "        \n",
    "print_ranges(X_Wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(mat: np.array) -> np.array:    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(mat)\n",
    "    return scaler.transform(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 \t 1.0\n",
      "0.0 \t 1.0\n",
      "0.0 \t 0.9999999999999999\n",
      "0.0 \t 1.0\n",
      "0.0 \t 1.0\n",
      "0.0 \t 1.0\n",
      "0.0 \t 0.9999999999999998\n",
      "0.0 \t 1.0\n",
      "0.0 \t 0.9999999999999999\n",
      "0.0 \t 0.9999999999999999\n",
      "0.0 \t 1.0\n",
      "0.0 \t 1.0\n",
      "0.0 \t 1.0\n"
     ]
    }
   ],
   "source": [
    "X_Wine = scale_data(X_Wine)\n",
    "print_ranges(X_Wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def design_matrix(mat: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Functia adauga o coloana de 1 inainte de prima coloana.\n",
    "    \"\"\"\n",
    "    \n",
    "    l, c = mat.shape\n",
    "    aux = np.ones((l, 1))\n",
    "    result = np.concatenate((aux, mat), axis = 1)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.84210526 0.1916996  ... 0.45528455 0.97069597 0.56134094]\n",
      " [1.         0.57105263 0.2055336  ... 0.46341463 0.78021978 0.55064194]\n",
      " [1.         0.56052632 0.3201581  ... 0.44715447 0.6959707  0.64693295]\n",
      " ...\n",
      " [1.         0.58947368 0.69960474 ... 0.08943089 0.10622711 0.39728959]\n",
      " [1.         0.56315789 0.36561265 ... 0.09756098 0.12820513 0.40085592]\n",
      " [1.         0.81578947 0.66403162 ... 0.10569106 0.12087912 0.20114123]]\n"
     ]
    }
   ],
   "source": [
    "X_Wine = design_matrix(X_Wine)\n",
    "print(X_Wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 1/3\n",
    "random_state = 5\n",
    "X_Wine_train, X_Wine_test, y_Wine_train, y_Wine_test = train_test_split(X_Wine, y_Wine, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy on prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_test(name:str, model, y_test, y_predicted) -> None:\n",
    "    accuracy_test = accuracy_score(y_test, y_predicted)\n",
    "    print(f'Accuracy ({name}): {accuracy_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy (5-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_5fold(name:str, model, X, y) -> None:\n",
    "    \n",
    "    scoring_acc = 'accuracy'\n",
    "    cv = 5\n",
    "    \n",
    "    score_accuracy = cross_val_score(model, X, y, cv=cv, scoring=scoring_acc)\n",
    "    print(f'Accuracy ({name}, {cv}-fold cv):\\n {score_accuracy}')\n",
    "    mean_score_accuracy = score_accuracy.mean()\n",
    "    print(f'Mean Accuracy ({name}, {cv}-fold cv): {mean_score_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 score (5-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_5fold(name:str, model, y_test, y_predicted) -> None:\n",
    "    \n",
    "    average = 'weighted'\n",
    "    cv = 5\n",
    "    \n",
    "    score_f1 = f1_score(y_test, y_predicted, average=average)\n",
    "    print(f'F1 score ({name}, {cv}-fold cv):\\n {score_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score measuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(name:str, scoring, model, X_train, y_train, X_test, y_test) -> None:\n",
    "    \n",
    "    cv = 5\n",
    "    \n",
    "    score_accuracy_train = cross_val_score(model, X_train, y_train, cv=cv, scoring=scoring)\n",
    "    print(f'Train {scoring} ({name}, {cv}-fold cv):\\n {score_accuracy_train}')\n",
    "\n",
    "    mean_score_accuracy_train = score_accuracy_train.mean()\n",
    "    print(f'Train Mean {scoring} ({name}, {cv}-fold cv): {mean_score_accuracy_train}')\n",
    "\n",
    "    print()\n",
    "\n",
    "    score_accuracy_test = cross_val_score(model, X_test, y_test, cv=cv, scoring=scoring)\n",
    "    print(f'Test {scoring} ({name}, {cv}-fold cv):\\n {score_accuracy_test}')\n",
    "\n",
    "    mean_score_accuracy_test = score_accuracy_test.mean()\n",
    "    print(f'Test Mean {scoring} ({name}, {cv}-fold cv): {mean_score_accuracy_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper(model, parameter_grid, X, y, X_train, y_train, X_test, y_test) -> None:\n",
    "    \n",
    "    \"\"\"\n",
    "    :param X: matricea de intrare\n",
    "    :param y: ground truth\n",
    "    \"\"\"\n",
    "    \n",
    "    cv = 5\n",
    "    nest_cv = 4\n",
    "    scoring = 'accuracy'\n",
    "    \n",
    "    #initializam GridSearch pentru Accuracy\n",
    "    grid_search = GridSearchCV(estimator = model,\n",
    "                               param_grid = parameter_grid,\n",
    "                               scoring = scoring,\n",
    "                               cv = cv,\n",
    "                               return_train_score = True)   \n",
    "    \n",
    "    #la fiecare rulare din 5-fold se face un 4-fold cross validation\n",
    "    scores = cross_val_score(grid_search, X, y, cv = nest_cv)\n",
    "\n",
    "    print('Accuracy:')\n",
    "    \n",
    "    print(f'Scores for {nest_cv}-fold cross validation:\\n {scores}')\n",
    "    print(f'Mean score for {nest_cv}-fold cross validation: {scores.mean()}')\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f'Best parameters (X_test): {best_params}')\n",
    "        \n",
    "    y_estimated = grid_search.predict(X_test)   \n",
    "    acc_score = accuracy_score(y_test, y_estimated)\n",
    "    print(f'accuracy_score(y_test, y_estimated): {acc_score}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(name: str, model, parameter_grid, X, y, X_train, y_train, X_test, y_test) -> None:\n",
    "    \n",
    "    #Fit\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #Predict\n",
    "    y_predicted = model.predict(X_test)\n",
    "    \n",
    "    #Accuracy after prediction\n",
    "    print('Accuracy on test set after prediction')\n",
    "    accuracy_test(name, model, y_test, y_predicted)\n",
    "    print()   \n",
    "\n",
    "    #Accuracy score (5-fold)\n",
    "    print('Accuracy score (5-fold)')\n",
    "    accuracy_5fold(name, model, X, y)\n",
    "    print()   \n",
    "\n",
    "    #F1 score (5-fold)\n",
    "    print('F1 score (5-fold)')\n",
    "    f1_5fold(name, model, y_test, y_predicted)\n",
    "    print()  \n",
    "\n",
    "    #Accuracy (5-fold) for training and test set\n",
    "    print('Accuracy (5-fold) for training and test set')\n",
    "    score(name, 'accuracy', model, X_train, y_train, X_test, y_test)\n",
    "    print()   \n",
    "\n",
    "    #F1 score (5-fold) for training and test set\n",
    "    print('F1 score (5-fold) for training and test set')\n",
    "    score(name, 'f1_macro', model, X_train, y_train, X_test, y_test)\n",
    "    print()\n",
    "\n",
    "    #Hyperparameter search\n",
    "    print('Hyperparameter search')\n",
    "    hyper(model, parameter_grid, X, y,\n",
    "          X_train, y_train,\n",
    "          X_test, y_test)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer Perceptron classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 10000\n",
    "model_MLPC_Wine = MLPClassifier(max_iter=max_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {'alpha' : list([0.001, 0.0001, 0.01, 0.005, 0.0005, 0.05])}\n",
    "apply_model('MLPC', model_MLPC_Wine, parameter_grid, X_Wine, y_Wine, X_Wine_train, y_Wine_train, X_Wine_test, y_Wine_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbours = 5\n",
    "model_KNN_Wine = KNeighborsClassifier(n_neighbors=n_neighbours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {'n_neighbors': list(range(1, 10)), 'p': [1, 2, 3, 4.7]}\n",
    "apply_model('KNN', model_KNN_Wine, parameter_grid, X_Wine, y_Wine, X_Wine_train, y_Wine_train, X_Wine_test, y_Wine_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 'rbf'\n",
    "model_SVC_Wine = SVC(kernel=kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set after prediction\n",
      "Accuracy (SVC): 0.9833333333333333\n",
      "\n",
      "Accuracy score (5-fold)\n",
      "Accuracy (SVC, 5-fold cv):\n",
      " [1.         0.97222222 0.97222222 1.         0.97142857]\n",
      "Mean Accuracy (SVC, 5-fold cv): 0.9831746031746033\n",
      "\n",
      "F1 score (5-fold)\n",
      "F1 score (SVC, 5-fold cv):\n",
      " 0.9833498268184068\n",
      "\n",
      "Accuracy (5-fold) for training and test set\n",
      "Train accuracy (SVC, 5-fold cv):\n",
      " [0.95833333 1.         1.         1.         0.95652174]\n",
      "Train Mean accuracy (SVC, 5-fold cv): 0.9829710144927537\n",
      "\n",
      "Test accuracy (SVC, 5-fold cv):\n",
      " [0.91666667 1.         1.         0.91666667 1.        ]\n",
      "Test Mean accuracy (SVC, 5-fold cv): 0.9666666666666666\n",
      "\n",
      "F1 score (5-fold) for training and test set\n",
      "Train f1_macro (SVC, 5-fold cv):\n",
      " [0.96023392 1.         1.         1.         0.96023392]\n",
      "Train Mean f1_macro (SVC, 5-fold cv): 0.984093567251462\n",
      "\n",
      "Test f1_macro (SVC, 5-fold cv):\n",
      " [0.92207792 1.         1.         0.9047619  1.        ]\n",
      "Test Mean f1_macro (SVC, 5-fold cv): 0.9653679653679653\n",
      "\n",
      "Hyperparameter search\n",
      "Accuracy:\n",
      "Scores for 4-fold cross validation:\n",
      " [0.93333333 0.95555556 0.97727273 0.97727273]\n",
      "Mean score for 4-fold cross validation: 0.9608585858585859\n",
      "Best parameters (X_test): {'C': 1, 'gamma': 0.1}\n",
      "accuracy_score(y_test, y_estimated): 0.95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameter_grid = {'C': [1, 10, 100], 'gamma': [0.01, 0.1]}\n",
    "apply_model('SVC', model_SVC_Wine, parameter_grid, X_Wine, y_Wine, X_Wine_train, y_Wine_train, X_Wine_test, y_Wine_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Hyperparameter search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
