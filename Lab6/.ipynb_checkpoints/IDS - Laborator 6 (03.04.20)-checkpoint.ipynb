{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laborator 6\n",
    "\n",
    "Versiunea 2020-04-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modele de clasificare\n",
    "\n",
    "Folositi 4 seturi de date pentru probleme de clasificare, plecand de la repository-urile specificate in Cursul 5; de exemplu, [ics.uci.edu](http://archive.ics.uci.edu/ml/datasets.php?format=mat&task=cla&att=&area=&numAtt=&numIns=&type=mvar&sort=nameUp&view=table). Cel putin doua seturi de date sa fie cu valori lipsa. \n",
    "\n",
    "\n",
    "1. (20 puncte) Aplicati o metoda de missing value imputation, unde este cazul; justificati si documentati metoda folosita.\n",
    "1. (numar de modele * numar de seturi de date \\* 1 punct = 20 de puncte) Pentru fiecare set de date aplicati 5 modele de clasificare din scikit learn. Pentru fiecare raportati: acuratete, scorul F1 - a se vedea [sklearn.metrics](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) - folosind 5 fold cross validation. Raportati mediile rezultatelor atat pentru fold-urile de antrenare, cat si pentru cele de testare. Rularile se vor face cu valori fixate ale hiperparametrilor. \n",
    "1. (numar modele * 4 puncte = 20 puncte) Documentati in jupyter notebook fiecare din modelele folosite, in limba romana. Daca acelasi algoritm e folosit pentru mai multe seturi de date, puteti face o sectiune separata cu documentarea algoritmilor + trimitere la algoritm. \n",
    "1. (numar de modele * numar de seturi de date * 1 punct = 20 de puncte) Raportati performanta fiecarui model, folosind 5 fold cross validation. Pentru fiecare din cele 5 rulari, cautati hiperparametrii optimi folosind 4-fold cross validation. Performanta modelului va fi raportata ca medie a celor  5 rulari. \n",
    "    *Observatie:* la fiecare din cele 5 rulari, hiperparametrii optimi pot diferi, din cauza datelor utilizate pentru antrenare/validare. \n",
    "\n",
    "Se acorda 20 de puncte din oficiu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemple de modele de clasificare:\n",
    "1. [Multi-layer Perceptron classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)\n",
    "1. [KNN](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)\n",
    "1. [SVM](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)\n",
    "1. <strike>[Gaussian processes](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessClassifier.html#sklearn.gaussian_process.GaussianProcessClassifier)</strike>\n",
    "1. <strike>[RBF](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.RBF.html#sklearn.gaussian_process.kernels.RBF)</strike>\n",
    "1. [Decision tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)\n",
    "1. [Random forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)\n",
    "1. <strike>[Gaussian Naive bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB)</strike> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print ('numpy:', np.__version__)\n",
    "print ('pandas:', pd.__version__)\n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer Perceptron Classifier (MLPC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Neighbours Classifier (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier (SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest (RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model_testing = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy on prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_test(name:str, model, y_test, y_predicted) -> None:\n",
    "    accuracy_test = accuracy_score(y_test, y_predicted)\n",
    "    print(f'Accuracy ({name}): {accuracy_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy (5-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_5fold(name:str, model, X, y) -> None:\n",
    "    \n",
    "    scoring_acc = 'accuracy'\n",
    "    cv = 5\n",
    "    \n",
    "    score_accuracy = cross_val_score(model, X, y, cv=cv, scoring=scoring_acc)\n",
    "    print(f'Accuracy ({name}, {cv}-fold cv):\\n {score_accuracy}')\n",
    "    mean_score_accuracy = score_accuracy.mean()\n",
    "    print(f'Mean Accuracy ({name}, {cv}-fold cv): {mean_score_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 score (5-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_5fold(name:str, model, y_test, y_predicted) -> None:\n",
    "    \n",
    "    average = 'weighted'\n",
    "    cv = 5\n",
    "    \n",
    "    score_f1 = f1_score(y_test, y_predicted, average=average)\n",
    "    print(f'F1 score ({name}, {cv}-fold cv):\\n {score_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score measuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(name:str, scoring, model, X_train, y_train, X_test, y_test) -> None:\n",
    "    \n",
    "    cv = 5\n",
    "    \n",
    "    score_accuracy_train = cross_val_score(model, X_train, y_train, cv=cv, scoring=scoring)\n",
    "    print(f'Train {scoring} ({name}, {cv}-fold cv):\\n {score_accuracy_train}')\n",
    "\n",
    "    mean_score_accuracy_train = score_accuracy_train.mean()\n",
    "    print(f'Train Mean {scoring} ({name}, {cv}-fold cv): {mean_score_accuracy_train}')\n",
    "\n",
    "    print()\n",
    "\n",
    "    score_accuracy_test = cross_val_score(model, X_test, y_test, cv=cv, scoring=scoring)\n",
    "    print(f'Test {scoring} ({name}, {cv}-fold cv):\\n {score_accuracy_test}')\n",
    "\n",
    "    mean_score_accuracy_test = score_accuracy_test.mean()\n",
    "    print(f'Test Mean {scoring} ({name}, {cv}-fold cv): {mean_score_accuracy_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper(model, parameter_grid, X, y, X_train, y_train, X_test, y_test) -> None:\n",
    "    \n",
    "    \"\"\"\n",
    "    :param X: matricea de intrare\n",
    "    :param y: ground truth\n",
    "    \"\"\"\n",
    "    \n",
    "    cv = 5\n",
    "    nest_cv = 4\n",
    "    scoring = 'accuracy'\n",
    "    n_jobs = 3\n",
    "    \n",
    "    #initializam GridSearch pentru Accuracy\n",
    "    grid_search = GridSearchCV(estimator = model,\n",
    "                               param_grid = parameter_grid,\n",
    "                               scoring = scoring,\n",
    "                               cv = cv,\n",
    "                               return_train_score = True,\n",
    "                               n_jobs = n_jobs)\n",
    "    \n",
    "    #la fiecare rulare din 5-fold se face un 4-fold cross validation\n",
    "    scores = cross_val_score(grid_search, X, y, cv = nest_cv, n_jobs = n_jobs)\n",
    "\n",
    "    print('Accuracy:')\n",
    "    \n",
    "    print(f'Scores for {nest_cv}-fold cross validation:\\n {scores}')\n",
    "    print(f'Mean score for {nest_cv}-fold cross validation: {scores.mean()}')\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f'Best parameters (X_test): {best_params}')\n",
    "        \n",
    "    y_estimated = grid_search.predict(X_test)   \n",
    "    acc_score = accuracy_score(y_test, y_estimated)\n",
    "    print(f'accuracy_score(y_test, y_estimated): {acc_score}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_separator(ch: str) -> None:\n",
    "    print(ch * 69)\n",
    "def print_separator_info(name:str, ch: str) -> None:\n",
    "    l = len(name)\n",
    "    r = 69 - l\n",
    "    if l % 2 == 0:\n",
    "        half = int(r/2) + 1\n",
    "        print(f'{ch * (half - 1)}{name}{ch * half}')    \n",
    "    else:\n",
    "        half = int(r/2)\n",
    "        print(f'{ch * half}{name}{ch * half}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(name: str, model, parameter_grid, X, y, X_train, y_train, X_test, y_test) -> None:\n",
    "    \n",
    "    #Fit\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #Predict\n",
    "    y_predicted = model.predict(X_test)\n",
    "    \n",
    "    #Accuracy after prediction\n",
    "    print('Accuracy on test set after prediction:')\n",
    "    accuracy_test(name, model, y_test, y_predicted)\n",
    "    print_separator('-')   \n",
    "\n",
    "    #Accuracy score (5-fold)\n",
    "    print('Accuracy score (5-fold):')\n",
    "    accuracy_5fold(name, model, X, y)\n",
    "    print_separator('-')   \n",
    "\n",
    "    #F1 score (5-fold)\n",
    "    print('F1 score (5-fold):')\n",
    "    f1_5fold(name, model, y_test, y_predicted)\n",
    "    print_separator('-')\n",
    "\n",
    "    #Accuracy (5-fold) for training and test set\n",
    "    print('Accuracy (5-fold) for training and test set:')\n",
    "    score(name, 'accuracy', model, X_train, y_train, X_test, y_test)\n",
    "    print_separator('-')\n",
    "\n",
    "    #F1 score (5-fold) for training and test set\n",
    "    print('F1 score (5-fold) for training and test set:')\n",
    "    score(name, 'f1_macro', model, X_train, y_train, X_test, y_test)\n",
    "    print_separator('-')\n",
    "\n",
    "    #Hyperparameter search\n",
    "    print('Hyperparameter search:')\n",
    "    hyper(model, parameter_grid, X, y,\n",
    "          X_train, y_train,\n",
    "          X_test, y_test)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run models on data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(X, y, X_train, y_train, X_test, y_test) -> None:\n",
    "    \n",
    "    print_separator_info('MLPC', '_')\n",
    "    #Multi-layer Perceptron classifier\n",
    "    max_iters = 10000\n",
    "    model_MLPC = MLPClassifier(max_iter=max_iters)\n",
    "    #apply Multi-layer Perceptron classifier\n",
    "    parameter_grid_MLPC = {'alpha' : [0.0001, 0.001, 0.01, 0.0005, 0.005, 0.05]}\n",
    "    apply_model('MLPC', model_MLPC, parameter_grid_MLPC, X, y, X_train, y_train, X_test, y_test)\n",
    "    print()\n",
    "    \n",
    "    print_separator_info('KNN', '_')\n",
    "    #KNN\n",
    "    n_neighbours = 5\n",
    "    model_KNN = KNeighborsClassifier(n_neighbors=n_neighbours)\n",
    "    #apply KNN\n",
    "    parameter_grid_KNN = {'n_neighbors': range(1, 10), 'p': [1, 2, 3, 4.7]}\n",
    "    apply_model('KNN', model_KNN, parameter_grid_KNN, X, y, X_train, y_train, X_test, y_test)\n",
    "    print()\n",
    "    \n",
    "    print_separator_info('SVC', '_')\n",
    "    #SVC\n",
    "    gamma = 'scale'\n",
    "    kernel = 'rbf'\n",
    "    model_SVC = SVC(kernel=kernel, gamma=gamma)\n",
    "    #apply SVC\n",
    "    parameter_grid_SVC = {'C': [0.1, 0.2, 0.3, 1, 10, 100], 'gamma': [0.01, 0.1, 0.03, 0.3, 0.5, 1]}\n",
    "    apply_model('SVC', model_SVC, parameter_grid_SVC, X, y, X_train, y_train, X_test, y_test)\n",
    "    print()\n",
    "    \n",
    "    print_separator_info('Decision Tree', '_')\n",
    "    #Decision Tree\n",
    "    criterion = 'gini'\n",
    "    model_DT = DecisionTreeClassifier(criterion=criterion)\n",
    "    #apply Decision Tree\n",
    "    parameter_grid_DT = {'max_depth': range(1, 10), 'min_samples_split': range(2, 40), 'min_impurity_decrease':[0.01, 0.02, 0.03, 0.05, 0.1]}\n",
    "    apply_model('Decision Tree', model_DT, parameter_grid_DT, X, y, X_train, y_train, X_test, y_test)\n",
    "    print()\n",
    "    \n",
    "    print_separator_info('Random Forest', '_')\n",
    "    #Random Forest\n",
    "    criterion = 'gini'\n",
    "    model_RF = RandomForestClassifier()\n",
    "    #apply Random Forest\n",
    "    parameter_grid_RF = {'max_depth': range(1, 10), 'min_samples_split': range(2, 5)}\n",
    "    apply_model('Random Forest', model_RF, parameter_grid_RF, X, y, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ranges(X):\n",
    "    \"\"\"\n",
    "    Functia printeaza minimul si maximul de pe fiecare coloana.\n",
    "    \"\"\"\n",
    "    \n",
    "    for col_index in range(X.shape[1]):\n",
    "        column = X[:, col_index]\n",
    "        print(f'{np.min(column)} \\t {np.max(column)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing value imputter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(data, columns) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Functia foloseste un KNNImputter sa umple valorile lipsa din setul de date.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_neighbors = 2\n",
    "    weights = 'uniform'\n",
    "    imputer = KNNImputer(n_neighbors = n_neighbors, weights = weights)\n",
    "    f_filled = imputer.fit_transform(data)\n",
    "    df = pd.DataFrame(f_filled, columns = columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(mat: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Functia scaleaza valorile matricei de intrare intre 0 si 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(mat)\n",
    "    return scaler.transform(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def design_matrix(mat: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Functia adauga o coloana de 1 inainte de prima coloana.\n",
    "    \"\"\"\n",
    "    \n",
    "    l, c = mat.shape\n",
    "    aux = np.ones((l, 1))\n",
    "    result = np.concatenate((aux, mat), axis = 1)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Satellite Image Data Set\n",
    "#### (https://sci2s.ugr.es/keel/dataset.php?cod=71)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_Sat = ['Sp11', 'Sp12', 'Sp13', 'Sp14', 'Sp15', 'Sp16', 'Sp17', 'Sp18', 'Sp19', \n",
    "               'Sp21', 'Sp22', 'Sp23', 'Sp24', 'Sp25', 'Sp26', 'Sp27', 'Sp28', 'Sp29', \n",
    "               'Sp31', 'Sp32', 'Sp33', 'Sp34', 'Sp35', 'Sp36', 'Sp37', 'Sp38', 'Sp39', \n",
    "               'Sp41', 'Sp42', 'Sp43', 'Sp44', 'Sp45', 'Sp46', 'Sp47', 'Sp48', 'Sp49', \n",
    "               'Class']\n",
    "path_Sat = r'./Data/SatImage/satimage.csv'\n",
    "sat_dataframe = pd.read_csv(path_Sat, header=None, names=columns_Sat)\n",
    "sat_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing value imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_data = fill_missing_values(sat_dataframe, columns_Sat)\n",
    "sat_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpret and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Sat = sat_data.values[:, :-1]\n",
    "y_Sat = sat_data.values[:, -1] #ultima coloana reprezinta ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_ranges(X_Sat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 1/3\n",
    "random_state = 5\n",
    "\n",
    "X_Sat_train, X_Sat_test, y_Sat_train, y_Sat_test = \\\n",
    "train_test_split(X_Sat, y_Sat, \n",
    "                 test_size=test_size, \n",
    "                 random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augment matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Sat_train = design_matrix(X_Sat_train)\n",
    "print(X_Sat_train)\n",
    "X_Sat_test = design_matrix(X_Sat_test)\n",
    "print(X_Sat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if run_model_testing:\n",
    "    run_models(X_Sat, y_Sat, \n",
    "               X_Sat_train, y_Sat_train, \n",
    "               X_Sat_test, y_Sat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Australian Satellite Image Data Set\n",
    "#### (https://sci2s.ugr.es/keel/dataset.php?cod=71)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_Aus = ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', \n",
    "             'A11', 'A12', 'A13', 'A14', \n",
    "             'Class']\n",
    "path_Aus = r'./Data/SatImage/australian.csv'\n",
    "aus_dataframe = pd.read_csv(path_Aus, header=None, names=names_Aus)\n",
    "aus_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing value imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aus_data = fill_missing_values(aus_dataframe, names_Aus)\n",
    "aus_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpret and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Aus = aus_data.values[:, :-1]\n",
    "y_Aus = aus_data.values[:, -1] #ultima coloana reprezinta ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_ranges(X_Aus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Aus = scale_data(X_Aus)\n",
    "print_ranges(X_Aus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 1/3\n",
    "random_state = 5\n",
    "\n",
    "X_Aus_train, X_Aus_test, y_Aus_train, y_Aus_test = \\\n",
    "train_test_split(X_Aus, y_Aus, \n",
    "                 test_size=test_size, \n",
    "                 random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augment matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Aus_train = design_matrix(X_Aus_train)\n",
    "print(X_Aus_train[:5, :5])\n",
    "X_Aus_test = design_matrix(X_Aus_test)\n",
    "print(X_Aus_test[:5, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if run_model_testing:\n",
    "    run_models(X_Aus, y_Aus, \n",
    "               X_Aus_train, y_Aus_train, \n",
    "               X_Aus_test, y_Aus_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine Data Set\n",
    "#### (http://archive.ics.uci.edu/ml/datasets/Wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path_Wine = r'./Data/Wine/wine.data'\n",
    "wine_data = pd.read_csv(path_Wine, header=None)\n",
    "wine_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpret and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Wine = wine_data.values[:, 1:]\n",
    "y_Wine = wine_data.values[:, 0] #prima coloana reprezinta ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_ranges(X_Wine)\n",
    "X_Wine = scale_data(X_Wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_ranges(X_Wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 1/3\n",
    "random_state = 5\n",
    "\n",
    "X_Wine_train, X_Wine_test, y_Wine_train, y_Wine_test = \\\n",
    "train_test_split(X_Wine, y_Wine, \n",
    "                 test_size=test_size, \n",
    "                 random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augment matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Wine_train = design_matrix(X_Wine_train)\n",
    "print(X_Wine_train[:5, :5])\n",
    "X_Wine_test = design_matrix(X_Wine_test)\n",
    "print(X_Wine_test[:5, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if run_model_testing:\n",
    "    run_models(X_Wine, y_Wine, \n",
    "               X_Wine_train, y_Wine_train, \n",
    "               X_Wine_test, y_Wine_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semeion Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_Semeion = r'./Data/Semeion/semeion.data'\n",
    "semeion_data = pd.read_csv(path_Semeion, sep=r'\\s+', header=None)\n",
    "semeion_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpret and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Semeion = semeion_data.values[:, :256]\n",
    "y_Semeion = semeion_data.values[:, 256:] #ultimele zece coloane reprezinta ground truth\n",
    "\n",
    "y_Semeion = np.argmax(y_Semeion, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 1/3\n",
    "random_state = 5\n",
    "\n",
    "X_Semeion_train, X_Semeion_test, y_Semeion_train, y_Semeion_test = \\\n",
    "train_test_split(X_Semeion, y_Semeion, \n",
    "                 test_size=test_size, \n",
    "                 random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augment matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Semeion_train = design_matrix(X_Semeion_train)\n",
    "print(X_Semeion_train)\n",
    "X_Semeion_test = design_matrix(X_Semeion_test)\n",
    "print(X_Semeion_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run models on data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if run_model_testing:\n",
    "    run_models(X_Semeion, y_Semeion, \n",
    "               X_Semeion_train, y_Semeion_train, \n",
    "               X_Semeion_test, y_Semeion_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
